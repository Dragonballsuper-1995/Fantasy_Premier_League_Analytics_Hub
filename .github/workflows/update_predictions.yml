name: Daily Prediction Update

on:
  # 1. Run on a schedule (cron):
  # This runs at 08:00 UTC every day.
  # (That's 1:30 PM IST, a good time for new data)
  schedule:
    - cron: '0 8 * * *'

  # 2. Allow manual runs:
  # This adds a "Run workflow" button to your GitHub Actions tab
  # so you can update it any time you want.
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out your repository's code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2: Set up a Python environment
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # A stable Python version

      # Step 3: Install all your Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas scikit-learn xgboost joblib

      # Step 4: Re-train the models (optional, but good practice)
      # This uses the new TRAIN_DATA_URL from your config.py
      - name: Re-train models
        run: python train_offline.py

      # Step 5: Run the main prediction script
      # This uses the new URLs from config.py to get the latest data
      # and generates a new 'predictions.json'
      - name: Run prediction script
        run: python main.py

      # Step 6: Commit the new predictions.json back to your repo
      # This action automatically checks if predictions.json has changed.
      # If it has, it creates a new commit and pushes it.
      # This push will automatically update your GitHub Pages site.
      - name: Commit and push updated predictions
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Automated: Update predictions.json with latest data"
          file_pattern: predictions.json
          commit_user_name: github-actions[bot]
          commit_user_email: github-actions[bot]@users.noreply.github.com